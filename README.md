# A Python Neural Network with Back-Propagation From Scratch

WIP

Features:

* Customisable number of layers and neurons for deep learning
* Optimised implementation utilising vector operations
* Written form scratch using only Numpy and Python
* Modern rectified linear units (ReLU) activation function


Data provided by [MNIST](http://yann.lecun.com/exdb/mnist/)